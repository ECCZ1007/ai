{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from typing import Callable, Optional\n",
    "import IPython\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create outputs folders\n",
    "os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Model Hyperparameters\n",
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "img_dim = 3 * 256 * 256\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network.\n",
    "    \n",
    "    Attempts to augoment an input image to look like a Monet painting.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim: int):\n",
    "        \"\"\"Initializes the Generator network.\n",
    "        \n",
    "        Args:\n",
    "            img_dim (int): Dimension of the image space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024, img_dim), \n",
    "            nn.Tanh() # For images, we want the values to be between -1 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network.\n",
    "    \n",
    "    Attempts to classify real and fake images from the dataset and the Generator network.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim: int):\n",
    "        \"\"\"Initializes the Discriminator network.\n",
    "        \n",
    "        Args:\n",
    "            img_dim (int): Dimension of the input space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Init the models\n",
    "gen_g = Generator(img_dim).to(device)\n",
    "gen_f = Generator(img_dim).to(device)\n",
    "disc = Discriminator(img_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image dataset.\n",
    "    \n",
    "    Loads images from a directory.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir: str, test_dir: str, transforms: Optional[Callable] = None):\n",
    "        \"\"\"Initializes the ImageDataset.\n",
    "        \n",
    "        Args:\n",
    "            train_dir (str): Directory containing the raw training images.\n",
    "            test_dir (str): Directory containing the raw training images.\n",
    "            transforms (Optional[Callable]): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.train_dir = sorted(glob.glob(os.path.join(train_dir, \"*.jpg\")))\n",
    "        self.test_dir = sorted(glob.glob(os.path.join(test_dir, \"*.jpg\")))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_image = Image.open(self.train_dir[index % len(self.train_dir)])\n",
    "        test_image = Image.open(self.test_dir[index % len(self.test_dir)])\n",
    "        if self.transforms:\n",
    "            train_image = self.transforms(train_image)\n",
    "            test_image = self.transforms(test_image)\n",
    "        return train_image, test_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_dir)\n",
    "# Image Transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Create the dataset\n",
    "ds = ImageDataset(train_dir='data/photo_jpg/', test_dir='data/monet_jpg/', transforms=transforms)\n",
    "\n",
    "# Create the data loader\n",
    "dataloader = DataLoader(ds, batch_size=32, shuffle=True, num_workers=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "opt_gen_g = torch.optim.Adam(gen_g.parameters(), lr=lr)\n",
    "opt_gen_f = torch.optim.Adam(gen_f.parameters(), lr=lr)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Loss\n",
    "criterion = nn.BCELoss()\n",
    "cycle_consistency_criterion = nn.MSELoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for raw_img, monet_img in tqdm(dataloader):\n",
    "        # Get the data\n",
    "        raw_img = raw_img.to(device)\n",
    "        raw_img = raw_img.reshape(raw_img.shape[0], -1)\n",
    "        monet_img = monet_img.to(device)\n",
    "        monet_img = monet_img.reshape(monet_img.shape[0], -1)        \n",
    "        \n",
    "        # Train the discriminator\n",
    "        disc_real = disc(monet_img)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        fake_img = gen_g(raw_img)\n",
    "        disc_fake = disc(fake_img)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "\n",
    "        # Train the generator g\n",
    "        lossG_1 = criterion(disc_fake, torch.ones_like(disc_fake))\n",
    "\n",
    "        # Train the generator f\n",
    "        og_img = gen_f(fake_img)\n",
    "        lossG_2 = cycle_consistency_criterion(og_img, raw_img)\n",
    "\n",
    "        lossG_g = (lossG_1 + lossG_2) /2\n",
    "        lossG_f = lossG_2\n",
    "\n",
    "        # Backward pass.\n",
    "        lossD.backward(retain_graph=True)\n",
    "        lossG_g.backward(retain_graph=True)\n",
    "        lossG_f.backward()\n",
    "\n",
    "        opt_gen_g.zero_grad()\n",
    "        opt_gen_f.zero_grad()\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        opt_gen_g.step()\n",
    "        opt_gen_f.step()\n",
    "        opt_disc.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss D: {lossD:.4f}, Loss G_g: {lossG_g:.4f}, Loss G_f: {lossG_f:.4f}\")\n",
    "    # Save model\n",
    "    torch.save(gen_g.state_dict(), f'outputs/gen_g.pth')\n",
    "    torch.save(gen_f.state_dict(), f'outputs/gen_f.pth')\n",
    "    torch.save(disc.state_dict(), f'outputs/disc.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a73d05bede605b914e881cac473083bc67bbc1abfd934ac332bf311f6ebb9017"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
