{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cirrascale/michaelliang/venv/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/cirrascale/michaelliang/venv/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Third-party imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from typing import Callable, Optional\n",
    "import IPython\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create outputs folders\n",
    "os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Model Hyperparameters\n",
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "img_dim = 3 * 256 * 256\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network.\n",
    "    \n",
    "    Attempts to augoment an input image to look like a Monet painting.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim: int):\n",
    "        \"\"\"Initializes the Generator network.\n",
    "        \n",
    "        Args:\n",
    "            img_dim (int): Dimension of the image space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(1024, img_dim), \n",
    "            nn.Tanh() # For images, we want the values to be between -1 and 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network.\n",
    "    \n",
    "    Attempts to classify real and fake images from the dataset and the Generator network.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dim: int):\n",
    "        \"\"\"Initializes the Discriminator network.\n",
    "        \n",
    "        Args:\n",
    "            img_dim (int): Dimension of the input space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "# Init the models\n",
    "gen_monet = Generator(img_dim).to(device)\n",
    "gen_raw = Generator(img_dim).to(device)\n",
    "disc_monet = Discriminator(img_dim).to(device)\n",
    "disc_raw = Discriminator(img_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Image dataset.\n",
    "    \n",
    "    Loads images from a directory.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir: str, test_dir: str, transforms: Optional[Callable] = None):\n",
    "        \"\"\"Initializes the ImageDataset.\n",
    "        \n",
    "        Args:\n",
    "            train_dir (str): Directory containing the raw training images.\n",
    "            test_dir (str): Directory containing the raw training images.\n",
    "            transforms (Optional[Callable]): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.train_dir = sorted(glob.glob(os.path.join(train_dir, \"*.jpg\")))\n",
    "        self.test_dir = sorted(glob.glob(os.path.join(test_dir, \"*.jpg\")))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_image = Image.open(self.train_dir[index % len(self.train_dir)])\n",
    "        test_image = Image.open(self.test_dir[index % len(self.test_dir)])\n",
    "        if self.transforms:\n",
    "            train_image = self.transforms(train_image)\n",
    "            test_image = self.transforms(test_image)\n",
    "        return train_image, test_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_dir)\n",
    "# Image Transforms\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "# Create the dataset\n",
    "ds = ImageDataset(train_dir='data/photo_jpg/', test_dir='data/monet_jpg/', transforms=transforms)\n",
    "\n",
    "# Create the data loader\n",
    "dataloader = DataLoader(ds, batch_size=32, shuffle=True, num_workers=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 0/220                   Loss D: 0.0307, loss G: 2.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 100/220 [00:22<00:25,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 100/220                   Loss D: 0.0121, loss G: 3.3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 200/220 [00:44<00:04,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50] Batch 200/220                   Loss D: 0.0625, loss G: 3.3053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:49<00:00,  4.44it/s]\n",
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Batch 0/220                   Loss D: 0.0000, loss G: 3.2804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 100/220 [00:22<00:25,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Batch 100/220                   Loss D: 0.0000, loss G: 3.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 200/220 [00:44<00:04,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Batch 200/220                   Loss D: 0.1014, loss G: 3.2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:49<00:00,  4.44it/s]\n",
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Batch 0/220                   Loss D: 0.0000, loss G: 3.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 100/220 [00:22<00:26,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Batch 100/220                   Loss D: 0.0000, loss G: 3.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 200/220 [00:44<00:04,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Batch 200/220                   Loss D: 0.0000, loss G: 3.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:49<00:00,  4.41it/s]\n",
      "  0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Batch 0/220                   Loss D: 0.0000, loss G: 3.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 52/220 [00:12<00:39,  4.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (raw_img, monet_img) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[0;32m---> 17\u001b[0m         raw_img \u001b[39m=\u001b[39m raw_img\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m         raw_img \u001b[39m=\u001b[39m raw_img\u001b[39m.\u001b[39mreshape(raw_img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m         monet_img \u001b[39m=\u001b[39m monet_img\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tensorboard.\n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MONET/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MONET/real\")\n",
    "\n",
    "# Optimizers\n",
    "opt_gen = torch.optim.Adam(list(gen_monet.parameters()) + list(gen_raw.parameters()), lr=lr)\n",
    "opt_disc = torch.optim.Adam(list(disc_monet.parameters()) + list(disc_raw.parameters()), lr=lr)\n",
    "\n",
    "# Loss\n",
    "L1 = nn.L1Loss() # Cycle consistency loss and identity loss\n",
    "mse = nn.MSELoss() # Adversarial loss\n",
    "\n",
    "step = 0\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (raw_img, monet_img) in enumerate(tqdm(dataloader)):\n",
    "        raw_img = raw_img.to(device)\n",
    "        raw_img = raw_img.reshape(raw_img.shape[0], -1)\n",
    "        monet_img = monet_img.to(device)\n",
    "        monet_img = monet_img.reshape(monet_img.shape[0], -1)          \n",
    "\n",
    "\n",
    "        # Train discriminators Monet and Raw\n",
    "        fake_monet = gen_monet(raw_img)\n",
    "        D_monet_real = disc_monet(monet_img)\n",
    "        D_monet_fake = disc_monet(fake_monet.detach())\n",
    "        D_monet_real_loss = mse(D_monet_real, torch.ones_like(D_monet_real))\n",
    "        D_monet_fake_loss = mse(D_monet_fake, torch.zeros_like(D_monet_fake))\n",
    "        D_monet_loss = D_monet_real_loss + D_monet_fake_loss\n",
    "\n",
    "        fake_raw = gen_raw(monet_img)\n",
    "        D_raw_real = disc_raw(raw_img)\n",
    "        D_raw_fake = disc_raw(fake_raw.detach())\n",
    "        D_raw_real_loss = mse(D_raw_real, torch.ones_like(D_raw_real))\n",
    "        D_raw_fake_loss = mse(D_raw_fake, torch.zeros_like(D_raw_fake))\n",
    "        D_raw_loss = D_raw_real_loss + D_raw_fake_loss\n",
    "\n",
    "        D_loss = (D_monet_loss + D_raw_loss)/2\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        D_loss.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train generators Monet and Raw\n",
    "        D_monet_fake = disc_monet(fake_monet)\n",
    "        D_raw_fake = disc_raw(fake_raw)\n",
    "        loss_G_monet = mse(D_monet_fake, torch.ones_like(D_monet_fake)) # Adversarial loss\n",
    "        loss_G_raw = mse(D_raw_fake, torch.ones_like(D_raw_fake)) # Adversarial loss\n",
    "\n",
    "        # Cycle loss\n",
    "        cycle_monet = gen_monet(fake_raw)\n",
    "        cycle_raw = gen_raw(fake_monet)\n",
    "        cycle_monet_loss = L1(monet_img, cycle_monet)\n",
    "        cycle_raw_loss = L1(raw_img, cycle_raw)\n",
    "\n",
    "        G_loss = (loss_G_monet + loss_G_raw) + (cycle_monet_loss + cycle_raw_loss)\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        G_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        step += 1\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {idx}/{len(dataloader)} \\\n",
    "                  Loss D: {D_loss:.4f}, loss G: {G_loss:.4f}\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                fake = gen_monet(raw_img)\n",
    "                # Unnormalise the image\n",
    "                fake = fake.reshape(-1, 3, 256, 256)\n",
    "                fake = fake * 0.5 + 0.5\n",
    "                # Save image\n",
    "                save_image(fake, f\"outputs/monet_{step}.png\")\n",
    "       \n",
    "\n",
    "    # Can we somehow see what the images look like as we train on tensorboard?\n",
    "    # Save model\n",
    "    torch.save(gen_monet.state_dict(), f'outputs/gen_monet_{epoch}.pth')\n",
    "    torch.save(gen_raw.state_dict(), f'outputs/gen_raw_{epoch}.pth')\n",
    "    torch.save(disc_monet.state_dict(), f'outputs/disc_monet_{epoch}.pth')\n",
    "    torch.save(disc_raw.state_dict(), f'outputs/disc_raw_{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a73d05bede605b914e881cac473083bc67bbc1abfd934ac332bf311f6ebb9017"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
