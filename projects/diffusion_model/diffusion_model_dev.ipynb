{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show training images\n",
    "def show_images(dataset, num_samples=20, cols=4):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img in enumerate(dataset):\n",
    "        if i == num_samples:\n",
    "            break\n",
    "        plt.subplot(num_samples // cols + 1, cols, i + 1)\n",
    "        plt.imshow(img[0])\n",
    "\n",
    "# data = torchvision.datasets.StanfordCars(root=\".\", download=True)\n",
    "# show_images(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward process - add noise to the images\n",
    "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
    "    return torch.linspace(start, end, timesteps)\n",
    "\n",
    "def get_index_from_list(vals, t, x_shape):\n",
    "    \"\"\"\n",
    "    Returns a specific index t of a passed list of values vals\n",
    "    while considering a batch dimension\n",
    "    \"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = vals.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "\n",
    "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Get nosied image at timestep t\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x_0.shape)\n",
    "    # Mean + Variance\n",
    "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
    "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
    "\n",
    "#define beta schedule\n",
    "T = 200\n",
    "betas = linear_beta_schedule(timesteps=T)\n",
    "\n",
    "# Precompute alphas for closed form solution\n",
    "alphas = 1.0 - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test noising on our dataset\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def load_transformed_dataset():\n",
    "    # Convert PIL image to tensor with some additional data augmentation.\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(), # scales between 0 and 1\n",
    "        transforms.Lambda(lambda t: t * 2.0 - 1.0) # scale between -1 and 1\n",
    "    ])\n",
    "    train = torchvision.datasets.StanfordCars(root=\".\", download=True, transform=transform)\n",
    "    test = torchvision.datasets.StanfordCars(root=\".\", download=True, transform=transform, split=\"test\")\n",
    "    return torch.utils.data.ConcatDataset([train, test])\n",
    "\n",
    "def show_tensor_image(image):\n",
    "    # Convert tensor image to pil image\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) /2), # converting this from normalized -1 to 1 values to 0 to 255 RGB values.\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)),\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    # Take first iamge of batch\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0, :, :, :]\n",
    "\n",
    "    plt.imshow(reverse_transforms(image))\n",
    "\n",
    "data = load_transformed_dataset()\n",
    "dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate forward diffusion process\n",
    "# for i, img in enumerate(dataloader):\n",
    "#     img = img[0]\n",
    "\n",
    "#     # Tensor with values 0, 20, 100 and 199\n",
    "#     t = torch.tensor([0, 20, 100, 199]).to(img.device)\n",
    "\n",
    "#     # Get noisy images at timesteps t\n",
    "#     x_t, noise = forward_diffusion_sample(img, t)\n",
    "\n",
    "#     # show\n",
    "#     for i in range(len(t)):\n",
    "#         # small plot\n",
    "#         plt.figure(figsize=(5, 5))\n",
    "#         plt.title(f\"Image at timestep {t[i]}\")\n",
    "#         show_tensor_image(x_t[i])\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet - simplified. TODO go deeper into understanding what is happening in the block and Unet forward function\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, up=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        if up:\n",
    "            self.conv1 = nn.Conv2d(2*in_channels, out_channels, 3, padding=1)\n",
    "            self.transform = nn.ConvTranspose2d(out_channels, out_channels, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "            self.transform = nn.Conv2d(out_channels, out_channels, 4, 2, 1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(3, stride=2)\n",
    "        self.bnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x, t, ):\n",
    "        h = self.bnorm(self.relu(self.conv1(x)))\n",
    "        time_emb = self.relu(self.time_mlp(t))\n",
    "        time_emb = time_emb[(..., ) + (None, ) * 2] # extend last 2 dimensions to get the shapes right.\n",
    "        h = h + time_emb\n",
    "        h = self.bnorm(self.relu(self.conv2(h)))\n",
    "        return self.transform(h)\n",
    "\n",
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    \"\"\"Encode positions with a sinusoid.\n",
    "    \n",
    "    I don't entirely understand how this is calculated but it's encoding positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat([embeddings.sin(), embeddings.cos()], dim=-1)\n",
    "        return embeddings\n",
    "        \n",
    "\n",
    "class SimpleUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        image_channels = 3\n",
    "        down_channels = (64, 128, 256, 512, 1024)\n",
    "        up_channels = (1024, 512, 256, 128, 64)\n",
    "        out_dim = 1\n",
    "        time_emb_dim = 32\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionalEmbedding(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1) # kernel size = 3 to maintain image size\n",
    "\n",
    "        # # Downsample\n",
    "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i + 1], time_emb_dim) for i in range(len(down_channels) - 1)])\n",
    "\n",
    "        # # Upsample\n",
    "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i + 1], time_emb_dim, up=True) for i in range(len(up_channels) - 1)])\n",
    "\n",
    "        # Output\n",
    "        self.output = nn.Conv2d(up_channels[-1], 3, out_dim) # maintain same image size as input.\n",
    "    \n",
    "    def forward(self, x, timestep):\n",
    "        # Embed time\n",
    "        t = self.time_mlp(timestep)\n",
    "        # Initial conv\n",
    "        x = self.conv0(x)\n",
    "\n",
    "        # Unet\n",
    "        residual_inputs = []\n",
    "        for down in self.downs:\n",
    "            x = down(x, t)\n",
    "            residual_inputs.append(x)\n",
    "        for up in self.ups:\n",
    "            residual_x = residual_inputs.pop()\n",
    "            x = torch.cat((x, residual_x), dim=1) # adding residual connection\n",
    "            x = up(x, t)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function - simple \n",
    "def get_loss(model, x_0, t):\n",
    "    x_noisy, noise = forward_diffusion_sample(x_0, t, device=\"cuda\")\n",
    "    noise_pred = model(x_noisy, t)\n",
    "    return F.l1_loss(noise, noise_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample new images, TODO write this later...\n",
    "@torch.no_grad()\n",
    "def sample_timestep(x, t):\n",
    "    \"\"\"Calls the model to predict the noise in the image and returns the denoised image. Applies noise to this image, if we are not in the last step yet.\"\"\"\n",
    "    betas_t = get_index_from_list(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
    "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
    "\n",
    "    # Call model\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
    "\n",
    "    if t == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        # Add noise\n",
    "        noise = torch.randn_like(model_mean)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_plot_image():\n",
    "    # Sample noise\n",
    "    img_size = IMG_SIZE\n",
    "    img = torch.randn(1, 3, img_size, img_size, device=device)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    num_images = 10\n",
    "    stepsize = int(T/num_images)\n",
    "\n",
    "    for i in range(0,T)[::-1]:\n",
    "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
    "        img = sample_timestep(img, t)\n",
    "        if i % stepsize == 0:\n",
    "            plt.subplot(1, num_images, i//stepsize + 1)\n",
    "            show_tensor_image(img.detach().cpu())\n",
    "    plt.show()\n",
    "\n",
    "# Sample trained images\n",
    "sample_plot_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/63 [00:01<01:37,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iteration 0, loss 0.8127855658531189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.18it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:20,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iteration 0, loss 0.31022199988365173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.21it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:22,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, iteration 0, loss 0.24982428550720215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.21it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, iteration 0, loss 0.22511009871959686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.18it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:09,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, iteration 0, loss 0.21327504515647888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.24it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:07,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, iteration 0, loss 0.1924629509449005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:20<00:00,  3.13it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:35,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, iteration 0, loss 0.1807977855205536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.15it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:20,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, iteration 0, loss 0.18164442479610443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.19it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:11,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, iteration 0, loss 0.1770012080669403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.24it/s]\n",
      "  2%|▏         | 1/63 [00:01<01:33,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, iteration 0, loss 0.17875781655311584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:19<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "# Training loop for one epoch on diffusion model on cuda\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SimpleUnet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(10):\n",
    "    for i, (x_0, _) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        x_0 = x_0.to(device)\n",
    "        t = torch.randint(0, T, (BATCH_SIZE, )).to(device)\n",
    "        loss = get_loss(model, x_0, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, iteration {i}, loss {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
